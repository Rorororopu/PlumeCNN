{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import analyzer\n",
    "import neural_network as nn\n",
    "import convolutional_neural_network as cnn\n",
    "import visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Set Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = [250,250]\n",
    "# Resolution should be consistent throughout the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Because the training dataset are individual, the list of each data just contain themselves.\n",
    "data1 = analyzer.Data(\"MORE_DATA/db_Y_0027.okc\", resolution) \n",
    "data2 = analyzer.Data(\"MORE_DATA/db_Y_0030.okc\", resolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this section if you want to use NN model\n",
    "\n",
    "array1, headers1, non_nan_indices1, num_grids1 = nn.data_arranger(data1.df)\n",
    "array2, headers2, non_nan_indices2, num_grids2 = nn.data_arranger(data2.df)\n",
    "\n",
    "# The learning rate, batch size, and epochs are proven to be working.\n",
    "\n",
    "nn_model = nn.model_create_compile(headers1, 0.05)\n",
    "\n",
    "nn_model, loss_hist = nn.model_train(nn_model, array1, 1000, 10)\n",
    "nn_model, loss_hist = nn.model_train(nn_model, array2, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this section if you want to use CNN model\n",
    "\n",
    "array1, headers1, indices1 = cnn.data_arranger(data1.df, resolution)\n",
    "array2, headers2, indices2 = cnn.data_arranger(data2.df, resolution)\n",
    "\n",
    "# The learning rate and epochs are proven to be working.\n",
    "\n",
    "cnn_model = cnn.model_2D_create_compile(headers1, 0.05, resolution)\n",
    "\n",
    "cnn_model, loss_hist = cnn.model_2D_train(cnn_model, array1, 3)\n",
    "cnn_model, loss_hist = cnn.model_2D_train(cnn_model, array2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose codes from these 3 codes below to run if you want to classify few individual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = analyzer.Data(\"MORE_DATA/db_Y_0049.okc\", resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is NN\n",
    "array3, headers3, non_nan_indices3, num_grids3 = nn.data_arranger(data3.df)\n",
    "data3.df = nn.model_classification(nn_model, array3, non_nan_indices3, num_grids3, data3.df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is CNN\n",
    "array3, headers3, indices3 = cnn.data_arranger(data3.df, resolution)\n",
    "data3.df = cnn.model_2D_classification(cnn_model, array3, indices3, data3.df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose codes from these 3 codes below to run if you want to classify a series of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paths_classify = [f\"MORE_DATA/db_Y_{i:04d}.okc\" for i in range(99)]\n",
    "\n",
    "Data_classify = [analyzer.Data(path, list_paths_classify, resolution) for path in list_paths_classify] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is NN\n",
    "for data in Data_classify:\n",
    "    array, headers, non_nan_indices, num_grids = nn.data_arranger(data.df)\n",
    "    data.df = nn.model_classification(nn_model, array, non_nan_indices, num_grids, data.df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is CNN\n",
    "for data in Data_classify:\n",
    "    array, headers, indices = cnn.data_arranger(data.df, data.resolution)\n",
    "    data.df = cnn.model_2D_classification(cnn_model, array, indices, data.df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose codes from these 2 codes below to run if you want to classify few individual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to export the image\n",
    "visualizer.plot_2D_df(data3.df, 'is_boundary', 'classification.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to export the csv file\n",
    "data3.df.to_csv('classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Code Zone\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 3D CSVs\n",
    "\n",
    "will remove empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "path = '3D_DATA/small_db_result'\n",
    "output_file = '3D_DATA/small_db.csv'\n",
    "\n",
    "files = [file for file in os.listdir(path) if file.endswith('.csv')]\n",
    "\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = None\n",
    "    \n",
    "    for index, filename in enumerate(files):\n",
    "        print(f\"merging file: {index + 1}/{len(files)}\", flush=True)\n",
    "        \n",
    "        with open(os.path.join(path, filename), 'r', encoding='utf-8') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            \n",
    "            header = next(reader)\n",
    "            \n",
    "            if writer is None:\n",
    "                writer = csv.writer(outfile)\n",
    "                writer.writerow(header)\n",
    "            \n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "print(\"All files merged successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Streamline 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizer import plot_3D_to_2D_slice_streamline\n",
    "\n",
    "plot_3D_to_2D_slice_streamline(input_file=\"3D_DATA/ra10e7_result/ra10e7_100.csv\", output_file=\"streamlines.html\", direction='y', seed_points_resolution=[20,20], max_time=0.2, cmap = 'viridis', axis_limits=[-0.5,0.5,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Streamline 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualizer\n",
    "visualizer.plot_3D_streamline( input_folder=\"3D_DATA/ra10e7_result\", output_file = 'test.html', point_resolution= [200,200,200], seed_points_resolution= [20,20,20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
