{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 11:25:49.223639: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-01 11:25:49.226253: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-01 11:25:49.230681: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-01 11:25:49.244700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-01 11:25:49.267549: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-01 11:25:49.274384: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-01 11:25:49.291275: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-01 11:25:51.666503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import analyzer\n",
    "import neural_network as nn\n",
    "import convolutional_neural_network as cnn\n",
    "import visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Set Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = [250,250]\n",
    "# Resolution should be consistent throughout the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to open the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to read the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to obtain the range of variables of the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to obtain the number of grid points of the file at MORE_DATA/db_Y_0027.okc...\n",
      "Obtained variable ranges of the file at MORE_DATA/db_Y_0027.okc.\n",
      "Trying to determine if the data is sliced...\n",
      "This data is sliced.\n",
      "Trying to open the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to read the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to obtain the range of variables of the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to obtain the number of grid points of the file at MORE_DATA/db_Y_0027.okc...\n",
      "Obtained variable ranges of the file at MORE_DATA/db_Y_0027.okc.\n",
      "Obtain the time for this data.\n",
      "Trying to open the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to read the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to obtain the range of variables of the file at MORE_DATA/db_Y_0027.okc...\n",
      "Trying to obtain the number of grid points of the file at MORE_DATA/db_Y_0027.okc...\n",
      "Obtained variable ranges of the file at MORE_DATA/db_Y_0027.okc.\n",
      "Finished mapping this data to your specified resolution.\n",
      "Regularizing parameters...\n",
      "Finished regularizing this data.\n",
      "Regularizing parameters...\n",
      "Finished regularizing this data.\n",
      "Regularizing parameters...\n",
      "Finished regularizing this data.\n",
      "Converting the temperature data to multi-dimensional array...\n",
      "Finished converting.\n",
      "Calculating the gradient of temperature...\n",
      "Finished calculating gradient.\n",
      "Converting the velocity_magnitude data to multi-dimensional array...\n",
      "Finished converting.\n",
      "Calculating the gradient of velocity_magnitude...\n",
      "Finished calculating gradient.\n",
      "Converting the z_velocity data to multi-dimensional array...\n",
      "Finished converting.\n",
      "Calculating the gradient of z_velocity...\n",
      "Finished calculating gradient.\n",
      "Trying to open the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to read the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to obtain the range of variables of the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to obtain the number of grid points of the file at MORE_DATA/db_Y_0030.okc...\n",
      "Obtained variable ranges of the file at MORE_DATA/db_Y_0030.okc.\n",
      "Trying to determine if the data is sliced...\n",
      "This data is sliced.\n",
      "Trying to open the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to read the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to obtain the range of variables of the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to obtain the number of grid points of the file at MORE_DATA/db_Y_0030.okc...\n",
      "Obtained variable ranges of the file at MORE_DATA/db_Y_0030.okc.\n",
      "Obtain the time for this data.\n",
      "Trying to open the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to read the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to obtain the range of variables of the file at MORE_DATA/db_Y_0030.okc...\n",
      "Trying to obtain the number of grid points of the file at MORE_DATA/db_Y_0030.okc...\n",
      "Obtained variable ranges of the file at MORE_DATA/db_Y_0030.okc.\n",
      "Finished mapping this data to your specified resolution.\n",
      "Regularizing parameters...\n",
      "Finished regularizing this data.\n",
      "Regularizing parameters...\n",
      "Finished regularizing this data.\n",
      "Regularizing parameters...\n",
      "Finished regularizing this data.\n",
      "Converting the temperature data to multi-dimensional array...\n",
      "Finished converting.\n",
      "Calculating the gradient of temperature...\n",
      "Finished calculating gradient.\n",
      "Converting the velocity_magnitude data to multi-dimensional array...\n",
      "Finished converting.\n",
      "Calculating the gradient of velocity_magnitude...\n",
      "Finished calculating gradient.\n",
      "Converting the z_velocity data to multi-dimensional array...\n",
      "Finished converting.\n",
      "Calculating the gradient of z_velocity...\n",
      "Finished calculating gradient.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Because the training dataset are individual, the list of each data just contain themselves.\n",
    "data1 = analyzer.Data(\"MORE_DATA/db_Y_0027.okc\", resolution) \n",
    "data2 = analyzer.Data(\"MORE_DATA/db_Y_0030.okc\", resolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this section if you want to use NN model\n",
    "\n",
    "array1, headers1, non_nan_indices1, num_grids1 = nn.data_arranger(data1.df)\n",
    "array2, headers2, non_nan_indices2, num_grids2 = nn.data_arranger(data2.df)\n",
    "\n",
    "# The learning rate, batch size, and epochs are proven to be working.\n",
    "\n",
    "nn_model = nn.model_create_compile(headers1, 0.05)\n",
    "\n",
    "nn_model, loss_hist = nn.model_train(nn_model, array1, 1000, 10)\n",
    "nn_model, loss_hist = nn.model_train(nn_model, array2, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this section if you want to use CNN model\n",
    "\n",
    "array1, headers1, indices1 = cnn.data_arranger(data1.df, resolution)\n",
    "array2, headers2, indices2 = cnn.data_arranger(data2.df, resolution)\n",
    "\n",
    "# The learning rate and epochs are proven to be working.\n",
    "\n",
    "cnn_model = cnn.model_2D_create_compile(headers1, 0.05, resolution)\n",
    "\n",
    "cnn_model, loss_hist = cnn.model_2D_train(cnn_model, array1, 3)\n",
    "cnn_model, loss_hist = cnn.model_2D_train(cnn_model, array2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose codes from these 3 codes below to run if you want to classify few individual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = analyzer.Data(\"3D_DATA/visit_ex_db.okc\", [50,50,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is NN\n",
    "array3, headers3, non_nan_indices3, num_grids3 = nn.data_arranger(data3.df)\n",
    "data3.df = nn.model_classification(nn_model, array3, non_nan_indices3, num_grids3, data3.df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is CNN\n",
    "array3, headers3, indices3 = cnn.data_arranger(data3.df, resolution)\n",
    "data3.df = cnn.model_2D_classification(cnn_model, array3, indices3, data3.df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose codes from these 3 codes below to run if you want to classify a series of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paths_classify = [f\"MORE_DATA/db_Y_{i:04d}.okc\" for i in range(99)]\n",
    "\n",
    "Data_classify = [analyzer.Data(path, list_paths_classify, resolution) for path in list_paths_classify] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is NN\n",
    "for data in Data_classify:\n",
    "    array, headers, non_nan_indices, num_grids = nn.data_arranger(data.df)\n",
    "    data.df = nn.model_classification(nn_model, array, non_nan_indices, num_grids, data.df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code if your model choice is CNN\n",
    "for data in Data_classify:\n",
    "    array, headers, indices = cnn.data_arranger(data.df, data.resolution)\n",
    "    data.df = cnn.model_2D_classification(cnn_model, array, indices, data.df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose codes from these 2 codes below to run if you want to classify few individual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to export the image\n",
    "visualizer.plot_2D_df(data3.df, 'is_boundary', 'classification.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to export the csv file\n",
    "data3.df.to_csv('classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose codes from these 2 codes below to run if you want to classify a series of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to export the image\n",
    "for i, data in enumerate(Data_classify):\n",
    "    visualizer.plot_2D_df(data.df, 'is_boundary', f'classification_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to export the csv file\n",
    "for i, data in enumerate(Data_classify):\n",
    "    data.df.to_csv(f'classification_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Code Zone\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
